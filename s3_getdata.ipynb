{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95124d7f-9dbd-4520-ac78-6b108b30adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from smart_open import open\n",
    "import random\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from typing import Dict, Tuple, Any, List  # https://fastapi.tiangolo.com/python-types/\n",
    "from pydantic import validate_arguments\n",
    "\n",
    "\n",
    "peekd_c = [\n",
    "    \"#0210AA\",\n",
    "    \"#07A8B2\",\n",
    "    \"#F642FA\",\n",
    "    \"#FF5F1D\",\n",
    "    \"#007C1B\",\n",
    "    \"#34C9B2\",\n",
    "    \"#A80505\",\n",
    "    \"#FFC003\",\n",
    "    \"#39D996\",\n",
    "    \"#6709CB\",\n",
    "    \"#FF2740\",\n",
    "    \"#FFEF29\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e5f98-72e5-4ffe-9141-9c0ea791c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate clients\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Load functions\n",
    "@validate_arguments\n",
    "def getListOfFiles(dirName: str) -> List[str]:\n",
    "    # create a list of file and sub directories\n",
    "    # names in the given directory\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "\n",
    "    return allFiles\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def get_all_s3_filepaths(s3_path: str) -> List[str]:\n",
    "    bucket, key, filename = split_s3_filepath(s3_path)\n",
    "    # Use paginator to overcome 1000 objects limit\n",
    "    paginator = s3_client.get_paginator(\"list_objects_v2\")\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=key)\n",
    "    s3_keys = []\n",
    "    for page in pages:\n",
    "        for obj in page[\"Contents\"]:\n",
    "            s3_keys.append(obj[\"Key\"])\n",
    "    # Recreate full s3 path\n",
    "    s3_filepaths = [f\"s3://{bucket}/{s3_key}\" for s3_key in s3_keys]\n",
    "    # Remove empty directory strings\n",
    "    s3_filepaths = [filepath for filepath in s3_filepaths if filepath[-1] is not \"/\"]\n",
    "    # Remove \"_SUCCESS\" files\n",
    "    s3_filepaths = [filepath for filepath in s3_filepaths if \"_SUCCESS\" not in filepath]\n",
    "    return s3_filepaths\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def split_s3_filepath(s3_filepath: str) -> Tuple[str, str, str]:\n",
    "    path_parts = s3_filepath.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = path_parts.pop(0)\n",
    "    key = \"/\".join(path_parts)\n",
    "    filename = path_parts[-1]\n",
    "    return bucket, key, filename\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def pd_read_file(local_filename: str) -> pd.DataFrame:\n",
    "    if '.' in local_filename:\n",
    "        filetype = local_filename.split(\".\")[-1]\n",
    "        if filetype == \"csv\":\n",
    "            df = pd.read_csv(local_filename)\n",
    "        elif filetype == \"parquet\":\n",
    "            df = pd.read_parquet(local_filename)\n",
    "        else:\n",
    "            raise Exception(f'filetype \"{filetype}\" is not supported at the moment')\n",
    "    else:\n",
    "        try:\n",
    "            df = pd.read_parquet(local_filename)\n",
    "        except:\n",
    "            raise Exception('filetype unknown.')\n",
    "    return df\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def download_s3(s3_filepath: str) -> pd.DataFrame:\n",
    "    # Get s3_bucket, s3_key, filename\n",
    "    s3_bucket, s3_key, filename = split_s3_filepath(s3_filepath)\n",
    "    if not filename:\n",
    "        print(f\"This is no file: {s3_filepath}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    local_filename = \"download_s3-\" + filename\n",
    "    # Download\n",
    "    try:\n",
    "        s3_client.download_file(s3_bucket, s3_key, local_filename)\n",
    "    except:\n",
    "        raise Exception\n",
    "\n",
    "    # Load result into memory\n",
    "    df = pd_read_file(local_filename)\n",
    "\n",
    "    # Remove downloaded result from local disk\n",
    "    if os.path.isfile(local_filename):\n",
    "        os.remove(local_filename)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
